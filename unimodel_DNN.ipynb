{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenchanti/TMD-framework/blob/main/unimodel_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuByagsA1ct5",
        "outputId": "881f02df-1937-46fc-9aa5-1dae653ae3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Epoch 1/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.8750\n",
            "Epoch 2/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.4874\n",
            "Epoch 3/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.4036\n",
            "Epoch 4/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.3638\n",
            "Epoch 5/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3377\n",
            "Epoch 6/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.3209\n",
            "Epoch 7/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.3069\n",
            "Epoch 8/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2966\n",
            "Epoch 9/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.2891\n",
            "Epoch 10/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2810\n",
            "Epoch 11/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2763\n",
            "Epoch 12/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2690\n",
            "Epoch 13/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2655\n",
            "Epoch 14/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2599\n",
            "Epoch 15/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2563\n",
            "Epoch 16/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2536\n",
            "Epoch 17/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2521\n",
            "Epoch 18/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2479\n",
            "Epoch 19/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2447\n",
            "Epoch 20/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2423\n",
            "Epoch 21/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2402\n",
            "Epoch 22/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2403\n",
            "Epoch 23/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.2367\n",
            "Epoch 24/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2369\n",
            "Epoch 25/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2347\n",
            "Epoch 26/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2334\n",
            "Epoch 27/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2303\n",
            "Epoch 28/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2303\n",
            "Epoch 29/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2297\n",
            "Epoch 30/30\n",
            "\u001b[1m10474/10474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2276\n",
            "\u001b[1m17955/17955\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.1987\n",
            "0.25s의 Test accuracy: 0.9353644251823425\n",
            "Epoch 1/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.6290 - loss: 0.9678\n",
            "Epoch 2/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7927 - loss: 0.5748\n",
            "Epoch 3/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.4824\n",
            "Epoch 4/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.4320\n",
            "Epoch 5/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.4028\n",
            "Epoch 6/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3792\n",
            "Epoch 7/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3587\n",
            "Epoch 8/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.3466\n",
            "Epoch 9/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3366\n",
            "Epoch 10/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.3271\n",
            "Epoch 11/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.3171\n",
            "Epoch 12/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.3117\n",
            "Epoch 13/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3053\n",
            "Epoch 14/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2988\n",
            "Epoch 15/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2964\n",
            "Epoch 16/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9023 - loss: 0.2860\n",
            "Epoch 17/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2846\n",
            "Epoch 18/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.2821\n",
            "Epoch 19/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.2790\n",
            "Epoch 20/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2751\n",
            "Epoch 21/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2705\n",
            "Epoch 22/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2697\n",
            "Epoch 23/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2663\n",
            "Epoch 24/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2652\n",
            "Epoch 25/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2610\n",
            "Epoch 26/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2579\n",
            "Epoch 27/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2575\n",
            "Epoch 28/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2542\n",
            "Epoch 29/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2524\n",
            "Epoch 30/30\n",
            "\u001b[1m5237/5237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2525\n",
            "\u001b[1m8978/8978\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.2333\n",
            "0.5s의 Test accuracy: 0.9232978224754333\n",
            "Epoch 1/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.5866 - loss: 1.0689\n",
            "Epoch 2/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.6610\n",
            "Epoch 3/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.5577\n",
            "Epoch 4/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.5062\n",
            "Epoch 5/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.4734\n",
            "Epoch 6/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8412 - loss: 0.4458\n",
            "Epoch 7/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.4244\n",
            "Epoch 8/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8553 - loss: 0.4094\n",
            "Epoch 9/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3947\n",
            "Epoch 10/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.3845\n",
            "Epoch 11/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3733\n",
            "Epoch 12/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3650\n",
            "Epoch 13/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3554\n",
            "Epoch 14/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3508\n",
            "Epoch 15/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3427\n",
            "Epoch 16/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.3369\n",
            "Epoch 17/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3331\n",
            "Epoch 18/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8859 - loss: 0.3253\n",
            "Epoch 19/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.3234\n",
            "Epoch 20/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3175\n",
            "Epoch 21/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.3152\n",
            "Epoch 22/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.3088\n",
            "Epoch 23/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8933 - loss: 0.3035\n",
            "Epoch 24/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3023\n",
            "Epoch 25/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3012\n",
            "Epoch 26/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2975\n",
            "Epoch 27/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2949\n",
            "Epoch 28/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2935\n",
            "Epoch 29/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2874\n",
            "Epoch 30/30\n",
            "\u001b[1m2619/2619\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2832\n",
            "\u001b[1m4489/4489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.3156\n",
            "1.0s의 Test accuracy: 0.8987816572189331\n",
            "Epoch 1/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5368 - loss: 1.1835\n",
            "Epoch 2/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7134 - loss: 0.7723\n",
            "Epoch 3/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7664 - loss: 0.6369\n",
            "Epoch 4/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.5733\n",
            "Epoch 5/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8094 - loss: 0.5257\n",
            "Epoch 6/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.4913\n",
            "Epoch 7/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.4666\n",
            "Epoch 8/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4409\n",
            "Epoch 9/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.4319\n",
            "Epoch 10/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8527 - loss: 0.4112\n",
            "Epoch 11/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.4008\n",
            "Epoch 12/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3870\n",
            "Epoch 13/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3772\n",
            "Epoch 14/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.3707\n",
            "Epoch 15/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3623\n",
            "Epoch 16/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3555\n",
            "Epoch 17/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3521\n",
            "Epoch 18/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8767 - loss: 0.3437\n",
            "Epoch 19/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.3333\n",
            "Epoch 20/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3329\n",
            "Epoch 21/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3268\n",
            "Epoch 22/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3230\n",
            "Epoch 23/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3164\n",
            "Epoch 24/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3108\n",
            "Epoch 25/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.3087\n",
            "Epoch 26/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3090\n",
            "Epoch 27/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3008\n",
            "Epoch 28/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.3042\n",
            "Epoch 29/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2920\n",
            "Epoch 30/30\n",
            "\u001b[1m1310/1310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.2939\n",
            "\u001b[1m2245/2245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3990\n",
            "2.0s의 Test accuracy: 0.8768448829650879\n",
            "Epoch 1/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5087 - loss: 1.2484\n",
            "Epoch 2/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.8322\n",
            "Epoch 3/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.6863\n",
            "Epoch 4/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.6047\n",
            "Epoch 5/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.5460\n",
            "Epoch 6/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.5074\n",
            "Epoch 7/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4757\n",
            "Epoch 8/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.4567\n",
            "Epoch 9/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4309\n",
            "Epoch 10/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4122\n",
            "Epoch 11/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3981\n",
            "Epoch 12/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3904\n",
            "Epoch 13/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.3759\n",
            "Epoch 14/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.3646\n",
            "Epoch 15/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3622\n",
            "Epoch 16/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.3445\n",
            "Epoch 17/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.3445\n",
            "Epoch 18/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3355\n",
            "Epoch 19/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.3253\n",
            "Epoch 20/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3187\n",
            "Epoch 21/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.3144\n",
            "Epoch 22/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.3096\n",
            "Epoch 23/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.3025\n",
            "Epoch 24/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8894 - loss: 0.3018\n",
            "Epoch 25/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2933\n",
            "Epoch 26/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2926\n",
            "Epoch 27/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2841\n",
            "Epoch 28/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2816\n",
            "Epoch 29/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2783\n",
            "Epoch 30/30\n",
            "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2756\n",
            "\u001b[1m1497/1497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.5438\n",
            "3.0s의 Test accuracy: 0.8510860204696655\n",
            "Epoch 1/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.4864 - loss: 1.3137\n",
            "Epoch 2/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6526 - loss: 0.9118\n",
            "Epoch 3/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.7630\n",
            "Epoch 4/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6747\n",
            "Epoch 5/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.6132\n",
            "Epoch 6/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.5646\n",
            "Epoch 7/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.5241\n",
            "Epoch 8/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4932\n",
            "Epoch 9/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.4679\n",
            "Epoch 10/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8375 - loss: 0.4393\n",
            "Epoch 11/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4272\n",
            "Epoch 12/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.4066\n",
            "Epoch 13/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8540 - loss: 0.3958\n",
            "Epoch 14/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.3808\n",
            "Epoch 15/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3639\n",
            "Epoch 16/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3600\n",
            "Epoch 17/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.3497\n",
            "Epoch 18/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.3400\n",
            "Epoch 19/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.3312\n",
            "Epoch 20/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3191\n",
            "Epoch 21/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3124\n",
            "Epoch 22/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3106\n",
            "Epoch 23/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.3066\n",
            "Epoch 24/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.2988\n",
            "Epoch 25/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2931\n",
            "Epoch 26/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2911\n",
            "Epoch 27/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2844\n",
            "Epoch 28/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2781\n",
            "Epoch 29/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2768\n",
            "Epoch 30/30\n",
            "\u001b[1m655/655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.2743\n",
            "\u001b[1m1123/1123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.6200\n",
            "4.0s의 Test accuracy: 0.8297131657600403\n",
            "Epoch 1/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4739 - loss: 1.3398\n",
            "Epoch 2/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6404 - loss: 0.9370\n",
            "Epoch 3/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.7686\n",
            "Epoch 4/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.6770\n",
            "Epoch 5/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.6154\n",
            "Epoch 6/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.5556\n",
            "Epoch 7/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.5150\n",
            "Epoch 8/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.4876\n",
            "Epoch 9/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4609\n",
            "Epoch 10/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.4316\n",
            "Epoch 11/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4094\n",
            "Epoch 12/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3898\n",
            "Epoch 13/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3721\n",
            "Epoch 14/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3616\n",
            "Epoch 15/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3486\n",
            "Epoch 16/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8752 - loss: 0.3373\n",
            "Epoch 17/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3203\n",
            "Epoch 18/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.3134\n",
            "Epoch 19/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3109\n",
            "Epoch 20/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2944\n",
            "Epoch 21/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.3026\n",
            "Epoch 22/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2818\n",
            "Epoch 23/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.2619\n",
            "Epoch 24/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.2776\n",
            "Epoch 25/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2586\n",
            "Epoch 26/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.2642\n",
            "Epoch 27/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2509\n",
            "Epoch 28/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2439\n",
            "Epoch 29/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2412\n",
            "Epoch 30/30\n",
            "\u001b[1m524/524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2368\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8235 - loss: 0.7353\n",
            "5.0s의 Test accuracy: 0.8209760785102844\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "import pandas as pd\n",
        "#import tensorflow_decision_forests as tfdf\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "path=\"/content/drive/MyDrive/merge\"\n",
        "\n",
        "\n",
        "# z-변환 함수 정의\n",
        "def z_normalize(data):\n",
        "    return (data - np.mean(data)) / np.std(data)\n",
        "\n",
        "\n",
        "ori_df=pd.DataFrame()\n",
        "mode=pd.DataFrame()\n",
        "for sample_files in os.listdir(path):\n",
        "\n",
        "    sample_file=pd.read_csv(path+\"//\"+sample_files)\n",
        "\n",
        "    #X=sample_file.iloc[:,:-2]\n",
        "    # y=sample_file[['Mode', 'Survay1']]\n",
        "    sample_mode_file=sample_file[['Mode']]\n",
        "    # sample_mode_file=pd.get_dummies(sample_mode_file,columns=[\"Mode\"])\n",
        "    col_names=sample_file.iloc[:,1:-2].columns\n",
        "\n",
        "    sample_file=sample_file.iloc[:,:-2]\n",
        "\n",
        "    # 각 센서 데이터에 대해 z-변환 적용\n",
        "    sample_file = sample_file.apply(z_normalize)\n",
        "    sample_file=sample_file.iloc[:,7:]\n",
        "    sample_file=sample_file.drop(\"Height\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Proxi\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Light\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Step\",axis=1)\n",
        "\n",
        "    col_names=sample_file.columns\n",
        "    ori_df=pd.concat([ori_df,sample_file],axis=0,ignore_index=True)\n",
        "    mode=pd.concat([mode,sample_mode_file],\n",
        "                      axis=0,ignore_index=True)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "ori_df = ori_df.apply(z_normalize)\n",
        "\n",
        "lst=[15,30 ,60,120,180,240,300]\n",
        "\n",
        "for i in lst:\n",
        "  df_mode=pd.DataFrame()\n",
        "  df_mode = mode.iloc[::i].reset_index(drop=True)\n",
        "  #for j in range(i,mode.shape[0]+1,i):\n",
        "   # df_mode=pd.concat([df_mode,mode[j-1:j]],ignore_index=True)\n",
        "\n",
        "\n",
        "#z_normalization\n",
        "\n",
        "  df=ori_df\n",
        "  df_columns=df.columns\n",
        "\n",
        "# 1. DataFrame을 NumPy 배열로 변환\n",
        "  df = df.values\n",
        "\n",
        "\n",
        "  df= np.reshape(df, (-1, i, 12))\n",
        "# df= np.reshape(df, (-1, 30, 12))\n",
        "# df= np.reshape(df, (-1, 60, 12))\n",
        "# df= np.reshape(df, (-1, 120, 12))\n",
        "# df= np.reshape(df, (-1, 180, 12))\n",
        "# df= np.reshape(df, (-1, 240, 12))\n",
        "\n",
        "# 결과 확인\n",
        "  X=df\n",
        "  y=df_mode\n",
        "  y=pd.get_dummies(y,columns=[\"Mode\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  epochs=30\n",
        "  learning_rates=0.001\n",
        "  batch_size=128\n",
        "\n",
        "\n",
        "    #데이터 분할\n",
        "  X_train,X_test=train_test_split(X,test_size=0.3,random_state=42)\n",
        "  y_train,y_test=train_test_split(y,test_size=0.3,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# 라벨을 one-hot 인코딩\n",
        "#train_labels = to_categorical(y_train)\n",
        "#test_labels = to_categorical(y_test)\n",
        "#\n",
        "\n",
        "# 2. DNN 모델 구축\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.InputLayer(shape=(i,12)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(32, activation='relu'))  # 첫 번째 히든 레이어\n",
        "  model.add(layers.Dense(64, activation='relu'))  # 두 번째 히든 레이어\n",
        "  model.add(layers.Dense(128, activation='relu'))  # 세 번째 히든 레이어\n",
        "\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "# 3. 모델 컴파일\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습\n",
        "  model.fit(X_train, y_train, epochs=30, batch_size=128)\n",
        "\n",
        "\n",
        "# 5. 테스트 데이터로 성능 평가\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "  print(f\"{i/60}s의 Test accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}