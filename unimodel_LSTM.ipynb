{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lenchanti/TMD-framework/blob/main/unimodel_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuByagsA1ct5",
        "outputId": "afe37594-9a48-4609-b4d6-f3acd4299360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 7ms/step - accuracy: 0.6783 - loss: 0.8504\n",
            "Epoch 2/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9107 - loss: 0.2721\n",
            "Epoch 3/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.1861\n",
            "Epoch 4/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.1457\n",
            "Epoch 5/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9611 - loss: 0.1204\n",
            "Epoch 6/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.1049\n",
            "Epoch 7/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9701 - loss: 0.0921\n",
            "Epoch 8/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9733 - loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0741\n",
            "Epoch 10/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0683\n",
            "Epoch 11/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.0635\n",
            "Epoch 12/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0579\n",
            "Epoch 13/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0543\n",
            "Epoch 14/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0506\n",
            "Epoch 15/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0481\n",
            "Epoch 16/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0448\n",
            "Epoch 17/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0422\n",
            "Epoch 18/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0406\n",
            "Epoch 19/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0385\n",
            "Epoch 20/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0361\n",
            "Epoch 21/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0349\n",
            "Epoch 22/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0334\n",
            "Epoch 23/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0315\n",
            "Epoch 24/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0309\n",
            "Epoch 25/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0294\n",
            "Epoch 26/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0284\n",
            "Epoch 27/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0271\n",
            "Epoch 28/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0266\n",
            "Epoch 29/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0247\n",
            "Epoch 30/30\n",
            "\u001b[1m8177/8177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0240\n",
            "\u001b[1m14018/14018\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0920\n",
            "0.25s의 Test accuracy: 0.9765315651893616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.6276 - loss: 0.9889\n",
            "Epoch 2/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8575 - loss: 0.4141\n",
            "Epoch 3/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9065 - loss: 0.2786\n",
            "Epoch 4/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.2163\n",
            "Epoch 5/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.1760\n",
            "Epoch 6/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.1513\n",
            "Epoch 7/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1324\n",
            "Epoch 8/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9616 - loss: 0.1169\n",
            "Epoch 9/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.1038\n",
            "Epoch 10/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9696 - loss: 0.0918\n",
            "Epoch 11/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.0843\n",
            "Epoch 12/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.0769\n",
            "Epoch 13/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9773 - loss: 0.0695\n",
            "Epoch 14/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0641\n",
            "Epoch 15/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0604\n",
            "Epoch 16/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0566\n",
            "Epoch 17/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0503\n",
            "Epoch 18/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0475\n",
            "Epoch 19/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0445\n",
            "Epoch 20/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0417\n",
            "Epoch 21/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.0411\n",
            "Epoch 22/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0380\n",
            "Epoch 23/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0357\n",
            "Epoch 24/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0334\n",
            "Epoch 25/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0329\n",
            "Epoch 26/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0300\n",
            "Epoch 27/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0289\n",
            "Epoch 28/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0280\n",
            "Epoch 29/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0269\n",
            "Epoch 30/30\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0261\n",
            "\u001b[1m7009/7009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1433\n",
            "0.5s의 Test accuracy: 0.965502917766571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 12ms/step - accuracy: 0.4869 - loss: 1.2940\n",
            "Epoch 2/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.7763 - loss: 0.6175\n",
            "Epoch 3/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.8519 - loss: 0.4271\n",
            "Epoch 4/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.8905 - loss: 0.3250\n",
            "Epoch 5/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.9146 - loss: 0.2562\n",
            "Epoch 6/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9306 - loss: 0.2084\n",
            "Epoch 7/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.1845\n",
            "Epoch 8/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9474 - loss: 0.1582\n",
            "Epoch 9/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.9526 - loss: 0.1435\n",
            "Epoch 10/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9605 - loss: 0.1207\n",
            "Epoch 11/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.1087\n",
            "Epoch 12/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.0959\n",
            "Epoch 13/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9704 - loss: 0.0893\n",
            "Epoch 14/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0799\n",
            "Epoch 15/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0745\n",
            "Epoch 16/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9789 - loss: 0.0644\n",
            "Epoch 17/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.9808 - loss: 0.0586\n",
            "Epoch 18/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0533\n",
            "Epoch 19/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0508\n",
            "Epoch 20/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0497\n",
            "Epoch 21/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0461\n",
            "Epoch 22/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0402\n",
            "Epoch 23/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.0405\n",
            "Epoch 24/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0375\n",
            "Epoch 25/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0361\n",
            "Epoch 26/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0330\n",
            "Epoch 27/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0319\n",
            "Epoch 28/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0285\n",
            "Epoch 29/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0303\n",
            "Epoch 30/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0261\n",
            "\u001b[1m3505/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1949\n",
            "1.0s의 Test accuracy: 0.9556447267532349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.4221 - loss: 1.4685\n",
            "Epoch 2/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - accuracy: 0.6683 - loss: 0.8726\n",
            "Epoch 3/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.7603 - loss: 0.6631\n",
            "Epoch 4/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.7996 - loss: 0.5516\n",
            "Epoch 5/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8430 - loss: 0.4462\n",
            "Epoch 6/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.8701 - loss: 0.3730\n",
            "Epoch 7/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.8915 - loss: 0.3185\n",
            "Epoch 8/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9078 - loss: 0.2722\n",
            "Epoch 9/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9163 - loss: 0.2498\n",
            "Epoch 10/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9290 - loss: 0.2112\n",
            "Epoch 11/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9382 - loss: 0.1866\n",
            "Epoch 12/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9458 - loss: 0.1650\n",
            "Epoch 13/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9517 - loss: 0.1482\n",
            "Epoch 14/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9559 - loss: 0.1334\n",
            "Epoch 15/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9629 - loss: 0.1148\n",
            "Epoch 16/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9637 - loss: 0.1125\n",
            "Epoch 17/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9677 - loss: 0.0990\n",
            "Epoch 18/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9714 - loss: 0.0890\n",
            "Epoch 19/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9729 - loss: 0.0832\n",
            "Epoch 20/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9763 - loss: 0.0750\n",
            "Epoch 21/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9786 - loss: 0.0674\n",
            "Epoch 22/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9792 - loss: 0.0648\n",
            "Epoch 23/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9807 - loss: 0.0576\n",
            "Epoch 24/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9833 - loss: 0.0535\n",
            "Epoch 25/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9835 - loss: 0.0521\n",
            "Epoch 26/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9851 - loss: 0.0461\n",
            "Epoch 27/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9854 - loss: 0.0472\n",
            "Epoch 28/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9863 - loss: 0.0451\n",
            "Epoch 29/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.9875 - loss: 0.0388\n",
            "Epoch 30/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9869 - loss: 0.0409\n",
            "\u001b[1m1753/1753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.2284\n",
            "2.0s의 Test accuracy: 0.9445692896842957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.2922 - loss: 1.7456\n",
            "Epoch 2/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.5089 - loss: 1.2499\n",
            "Epoch 3/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.6406 - loss: 0.9332\n",
            "Epoch 4/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - accuracy: 0.7395 - loss: 0.7184\n",
            "Epoch 5/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.7857 - loss: 0.5889\n",
            "Epoch 6/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.8165 - loss: 0.5066\n",
            "Epoch 7/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8497 - loss: 0.4269\n",
            "Epoch 8/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.8711 - loss: 0.3701\n",
            "Epoch 9/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - accuracy: 0.8907 - loss: 0.3178\n",
            "Epoch 10/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9055 - loss: 0.2742\n",
            "Epoch 11/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.9142 - loss: 0.2544\n",
            "Epoch 12/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - accuracy: 0.9305 - loss: 0.2113\n",
            "Epoch 13/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.9371 - loss: 0.1877\n",
            "Epoch 14/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9432 - loss: 0.1726\n",
            "Epoch 15/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9486 - loss: 0.1578\n",
            "Epoch 16/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9405 - loss: 0.1820\n",
            "Epoch 17/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9556 - loss: 0.1365\n",
            "Epoch 18/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9626 - loss: 0.1173\n",
            "Epoch 19/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9664 - loss: 0.1057\n",
            "Epoch 20/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.9696 - loss: 0.0948\n",
            "Epoch 21/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.9717 - loss: 0.0902\n",
            "Epoch 22/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 24ms/step - accuracy: 0.9746 - loss: 0.0797\n",
            "Epoch 23/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.9780 - loss: 0.0683\n",
            "Epoch 24/30\n",
            "\u001b[1m252/682\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9723 - loss: 0.0835"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "import pandas as pd\n",
        "#import tensorflow_decision_forests as tfdf\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "path=\"/content/drive/MyDrive/merge\"\n",
        "\n",
        "\n",
        "# z-변환 함수 정의\n",
        "def z_normalize(data):\n",
        "    return (data - np.mean(data)) / np.std(data)\n",
        "\n",
        "\n",
        "ori_df=pd.DataFrame()\n",
        "mode=pd.DataFrame()\n",
        "for sample_files in os.listdir(path):\n",
        "\n",
        "    sample_file=pd.read_csv(path+\"//\"+sample_files)\n",
        "\n",
        "    #X=sample_file.iloc[:,:-2]\n",
        "    # y=sample_file[['Mode', 'Survay1']]\n",
        "    sample_mode_file=sample_file[['Mode']]\n",
        "    # sample_mode_file=pd.get_dummies(sample_mode_file,columns=[\"Mode\"])\n",
        "    col_names=sample_file.iloc[:,1:-2].columns\n",
        "\n",
        "    sample_file=sample_file.iloc[:,:-2]\n",
        "\n",
        "    # 각 센서 데이터에 대해 z-변환 적용\n",
        "    sample_file = sample_file.apply(z_normalize)\n",
        "    sample_file=sample_file.iloc[:,7:]\n",
        "    sample_file=sample_file.drop(\"Height\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Proxi\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Light\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Step\",axis=1)\n",
        "\n",
        "    col_names=sample_file.columns\n",
        "    ori_df=pd.concat([ori_df,sample_file],axis=0,ignore_index=True)\n",
        "    mode=pd.concat([mode,sample_mode_file],\n",
        "                      axis=0,ignore_index=True)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "ori_df = ori_df.apply(z_normalize)\n",
        "\n",
        "lst=[15,30 ,60,120,180,240,300]\n",
        "\n",
        "for i in lst:\n",
        "  df_mode=pd.DataFrame()\n",
        "  df_mode = mode.iloc[::i].reset_index(drop=True)\n",
        "  #for j in range(i,mode.shape[0]+1,i):\n",
        "   # df_mode=pd.concat([df_mode,mode[j-1:j]],ignore_index=True)\n",
        "\n",
        "\n",
        "#z_normalization\n",
        "\n",
        "  df=ori_df\n",
        "  df_columns=df.columns\n",
        "\n",
        "# 1. DataFrame을 NumPy 배열로 변환\n",
        "  df = df.values\n",
        "\n",
        "# 2. (22428000, 12) 배열을 (?, 120, 12) 배열로 변환\n",
        "# 22428000이 120으로 나눠 떨어지기 때문에 재구성 가능\n",
        "\n",
        "  df= np.reshape(df, (-1, i, 12))\n",
        "# df= np.reshape(df, (-1, 30, 12))\n",
        "# df= np.reshape(df, (-1, 60, 12))\n",
        "# df= np.reshape(df, (-1, 120, 12))\n",
        "# df= np.reshape(df, (-1, 180, 12))\n",
        "# df= np.reshape(df, (-1, 240, 12))\n",
        "\n",
        "# 결과 확인\n",
        "  X=df\n",
        "  y=df_mode\n",
        "  y=pd.get_dummies(y,columns=[\"Mode\"])\n",
        "\n",
        "\n",
        "# 1. DataFrame을 NumPy 배열로 변환\n",
        "  #y = y.values\n",
        "\n",
        "# 2. (22428000, 12) 배열을 (?, 120, 12) 배열로 변환\n",
        "# 22428000이 120으로 나눠 떨어지기 때문에 재구성 가능\n",
        "  #y= np.reshape(y, (-1, 7))\n",
        "\n",
        "\n",
        "\n",
        "  epochs=30\n",
        "  learning_rates=0.001\n",
        "  batch_size=128\n",
        "\n",
        "\n",
        "    #데이터 분할\n",
        "  X_train,X_test=train_test_split(X,test_size=0.3,random_state=42)\n",
        "  y_train,y_test=train_test_split(y,test_size=0.3,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# 라벨을 one-hot 인코딩\n",
        "#train_labels = to_categorical(y_train)\n",
        "#test_labels = to_categorical(y_test)\n",
        "#\n",
        "\n",
        "# 2. DNN 모델 구축\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=True,input_shape=(i,12)))\n",
        "\n",
        "# 두 번째 LSTM 레이어 (128 memory units, return_sequences=False)\n",
        "# return_sequences=False로 마지막 time step에 대한 출력만 반환\n",
        "  model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Fully connected layer (Output layer)\n",
        "# 예시로 Dense layer를 추가 (클래스 개수에 맞게 output_dim 조정)\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  model.add(layers.Dense(256, activation='relu'))  # 세 번째 히든 레이어\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "# 3. 모델 컴파일\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습\n",
        "  model.fit(X_train, y_train, epochs=30, batch_size=128)\n",
        "\n",
        "\n",
        "# 5. 테스트 데이터로 성능 평가\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "  print(f\"{i/60}s의 Test accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "import pandas as pd\n",
        "#import tensorflow_decision_forests as tfdf\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "path=\"/content/drive/MyDrive/merge\"\n",
        "\n",
        "\n",
        "# z-변환 함수 정의\n",
        "def z_normalize(data):\n",
        "    return (data - np.mean(data)) / np.std(data)\n",
        "\n",
        "\n",
        "ori_df=pd.DataFrame()\n",
        "mode=pd.DataFrame()\n",
        "for sample_files in os.listdir(path):\n",
        "\n",
        "    sample_file=pd.read_csv(path+\"//\"+sample_files)\n",
        "\n",
        "    #X=sample_file.iloc[:,:-2]\n",
        "    # y=sample_file[['Mode', 'Survay1']]\n",
        "    sample_mode_file=sample_file[['Mode']]\n",
        "    # sample_mode_file=pd.get_dummies(sample_mode_file,columns=[\"Mode\"])\n",
        "    col_names=sample_file.iloc[:,1:-2].columns\n",
        "\n",
        "    sample_file=sample_file.iloc[:,:-2]\n",
        "\n",
        "    # 각 센서 데이터에 대해 z-변환 적용\n",
        "    sample_file = sample_file.apply(z_normalize)\n",
        "    sample_file=sample_file.iloc[:,7:]\n",
        "    sample_file=sample_file.drop(\"Height\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Proxi\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Light\",axis=1)\n",
        "    sample_file=sample_file.drop(\"Step\",axis=1)\n",
        "\n",
        "    col_names=sample_file.columns\n",
        "    ori_df=pd.concat([ori_df,sample_file],axis=0,ignore_index=True)\n",
        "    mode=pd.concat([mode,sample_mode_file],\n",
        "                      axis=0,ignore_index=True)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "ori_df = ori_df.apply(z_normalize)\n",
        "\n",
        "lst=[60,120,180,240,300]\n",
        "\n",
        "for i in lst:\n",
        "  df_mode=pd.DataFrame()\n",
        "  df_mode = mode.iloc[::i].reset_index(drop=True)\n",
        "  #for j in range(i,mode.shape[0]+1,i):\n",
        "   # df_mode=pd.concat([df_mode,mode[j-1:j]],ignore_index=True)\n",
        "\n",
        "\n",
        "#z_normalization\n",
        "\n",
        "  df=ori_df\n",
        "  df_columns=df.columns\n",
        "\n",
        "# 1. DataFrame을 NumPy 배열로 변환\n",
        "  df = df.values\n",
        "\n",
        "# 2. (22428000, 12) 배열을 (?, 120, 12) 배열로 변환\n",
        "# 22428000이 120으로 나눠 떨어지기 때문에 재구성 가능\n",
        "\n",
        "  df= np.reshape(df, (-1, i, 12))\n",
        "# df= np.reshape(df, (-1, 30, 12))\n",
        "# df= np.reshape(df, (-1, 60, 12))\n",
        "# df= np.reshape(df, (-1, 120, 12))\n",
        "# df= np.reshape(df, (-1, 180, 12))\n",
        "# df= np.reshape(df, (-1, 240, 12))\n",
        "\n",
        "# 결과 확인\n",
        "  X=df\n",
        "  y=df_mode\n",
        "  y=pd.get_dummies(y,columns=[\"Mode\"])\n",
        "\n",
        "\n",
        "# 1. DataFrame을 NumPy 배열로 변환\n",
        "  #y = y.values\n",
        "\n",
        "# 2. (22428000, 12) 배열을 (?, 120, 12) 배열로 변환\n",
        "# 22428000이 120으로 나눠 떨어지기 때문에 재구성 가능\n",
        "  #y= np.reshape(y, (-1, 7))\n",
        "\n",
        "\n",
        "\n",
        "  epochs=30\n",
        "  learning_rates=0.001\n",
        "  batch_size=128\n",
        "\n",
        "\n",
        "    #데이터 분할\n",
        "  X_train,X_test=train_test_split(X,test_size=0.3,random_state=42)\n",
        "  y_train,y_test=train_test_split(y,test_size=0.3,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# 라벨을 one-hot 인코딩\n",
        "#train_labels = to_categorical(y_train)\n",
        "#test_labels = to_categorical(y_test)\n",
        "#\n",
        "\n",
        "# 2. DNN 모델 구축\n",
        "  model = models.Sequential()\n",
        "\n",
        "  model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=True,input_shape=(i,12)))\n",
        "\n",
        "# 두 번째 LSTM 레이어 (128 memory units, return_sequences=False)\n",
        "# return_sequences=False로 마지막 time step에 대한 출력만 반환\n",
        "  model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
        "\n",
        "# Fully connected layer (Output layer)\n",
        "# 예시로 Dense layer를 추가 (클래스 개수에 맞게 output_dim 조정)\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  model.add(layers.Dense(256, activation='relu'))  # 세 번째 히든 레이어\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "# 3. 모델 컴파일\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습\n",
        "  model.fit(X_train, y_train, epochs=30, batch_size=128)\n",
        "\n",
        "\n",
        "# 5. 테스트 데이터로 성능 평가\n",
        "  test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "  print(f\"{i/60}s의 Test accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_jUWxvc8SJa",
        "outputId": "73700037-2eb5-42ab-c8fd-aea8dc34c83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 12ms/step - accuracy: 0.4316 - loss: 1.4150\n",
            "Epoch 2/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.7063 - loss: 0.8129\n",
            "Epoch 3/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.7834 - loss: 0.6079\n",
            "Epoch 4/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.8058 - loss: 0.5514\n",
            "Epoch 5/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.8681 - loss: 0.3871\n",
            "Epoch 6/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.8920 - loss: 0.3192\n",
            "Epoch 7/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9102 - loss: 0.2705\n",
            "Epoch 8/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9232 - loss: 0.2307\n",
            "Epoch 9/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.9323 - loss: 0.2037\n",
            "Epoch 10/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9416 - loss: 0.1759\n",
            "Epoch 11/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9488 - loss: 0.1570\n",
            "Epoch 12/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9522 - loss: 0.1440\n",
            "Epoch 13/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9589 - loss: 0.1253\n",
            "Epoch 14/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.9615 - loss: 0.1168\n",
            "Epoch 15/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.1050\n",
            "Epoch 16/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9677 - loss: 0.0971\n",
            "Epoch 17/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - accuracy: 0.9712 - loss: 0.0878\n",
            "Epoch 18/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.9731 - loss: 0.0820\n",
            "Epoch 19/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9752 - loss: 0.0747\n",
            "Epoch 20/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9767 - loss: 0.0706\n",
            "Epoch 21/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0633\n",
            "Epoch 22/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.0601\n",
            "Epoch 23/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.0556\n",
            "Epoch 24/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.0512\n",
            "Epoch 25/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0473\n",
            "Epoch 26/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.0463\n",
            "Epoch 27/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0418\n",
            "Epoch 28/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0426\n",
            "Epoch 29/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0393\n",
            "Epoch 30/30\n",
            "\u001b[1m2045/2045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0357\n",
            "\u001b[1m3505/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1925\n",
            "1.0s의 Test accuracy: 0.9520331621170044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - accuracy: 0.3548 - loss: 1.6379\n",
            "Epoch 2/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.5024 - loss: 1.2669\n",
            "Epoch 3/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.5813 - loss: 1.0730\n",
            "Epoch 4/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.6404 - loss: 0.9298\n",
            "Epoch 5/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.6909 - loss: 0.8157\n",
            "Epoch 6/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.7371 - loss: 0.7030\n",
            "Epoch 7/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.7574 - loss: 0.6532\n",
            "Epoch 8/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.7777 - loss: 0.6134\n",
            "Epoch 9/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8185 - loss: 0.5008\n",
            "Epoch 10/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.7808 - loss: 0.5881\n",
            "Epoch 11/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.7411 - loss: 0.6830\n",
            "Epoch 12/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.7891 - loss: 0.5610\n",
            "Epoch 13/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8167 - loss: 0.4944\n",
            "Epoch 14/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.7944 - loss: 0.5644\n",
            "Epoch 15/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.8217 - loss: 0.4910\n",
            "Epoch 16/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.8324 - loss: 0.4692\n",
            "Epoch 17/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.8514 - loss: 0.4188\n",
            "Epoch 18/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8126 - loss: 0.5112\n",
            "Epoch 19/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.8748 - loss: 0.3541\n",
            "Epoch 20/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.8869 - loss: 0.3236\n",
            "Epoch 21/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9039 - loss: 0.2826\n",
            "Epoch 22/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9140 - loss: 0.2536\n",
            "Epoch 23/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9213 - loss: 0.2312\n",
            "Epoch 24/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9296 - loss: 0.2090\n",
            "Epoch 25/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9320 - loss: 0.1973\n",
            "Epoch 26/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9323 - loss: 0.2010\n",
            "Epoch 27/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9289 - loss: 0.2127\n",
            "Epoch 28/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9493 - loss: 0.1512\n",
            "Epoch 29/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.9536 - loss: 0.1402\n",
            "Epoch 30/30\n",
            "\u001b[1m1023/1023\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9569 - loss: 0.1284\n",
            "\u001b[1m1753/1753\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.2244\n",
            "2.0s의 Test accuracy: 0.9307829737663269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.3723 - loss: 1.6181\n",
            "Epoch 2/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.5525 - loss: 1.1529\n",
            "Epoch 3/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.6670 - loss: 0.9171\n",
            "Epoch 4/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.6676 - loss: 0.9146\n",
            "Epoch 5/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.7288 - loss: 0.7534\n",
            "Epoch 6/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.7585 - loss: 0.6661\n",
            "Epoch 7/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.7656 - loss: 0.6423\n",
            "Epoch 8/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.7665 - loss: 0.6394\n",
            "Epoch 9/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8055 - loss: 0.5357\n",
            "Epoch 10/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8249 - loss: 0.4820\n",
            "Epoch 11/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8382 - loss: 0.4432\n",
            "Epoch 12/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.8584 - loss: 0.3922\n",
            "Epoch 13/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.8697 - loss: 0.3657\n",
            "Epoch 14/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.8848 - loss: 0.3281\n",
            "Epoch 15/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.8989 - loss: 0.2909\n",
            "Epoch 16/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9076 - loss: 0.2687\n",
            "Epoch 17/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9177 - loss: 0.2405\n",
            "Epoch 18/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9266 - loss: 0.2145\n",
            "Epoch 19/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9288 - loss: 0.2083\n",
            "Epoch 20/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9360 - loss: 0.1904\n",
            "Epoch 21/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - accuracy: 0.9413 - loss: 0.1790\n",
            "Epoch 22/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9492 - loss: 0.1504\n",
            "Epoch 23/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9512 - loss: 0.1444\n",
            "Epoch 24/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9554 - loss: 0.1326\n",
            "Epoch 25/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.9588 - loss: 0.1225\n",
            "Epoch 26/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9606 - loss: 0.1192\n",
            "Epoch 27/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.9639 - loss: 0.1070\n",
            "Epoch 28/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9685 - loss: 0.0946\n",
            "Epoch 29/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9665 - loss: 0.0998\n",
            "Epoch 30/30\n",
            "\u001b[1m682/682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.0939\n",
            "\u001b[1m1169/1169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9256 - loss: 0.2613\n",
            "3.0s의 Test accuracy: 0.9252274036407471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.3400 - loss: 1.6831\n",
            "Epoch 2/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.4533 - loss: 1.3633\n",
            "Epoch 3/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.4679 - loss: 1.3544\n",
            "Epoch 4/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.5697 - loss: 1.1218\n",
            "Epoch 5/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.6270 - loss: 0.9862\n",
            "Epoch 6/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.6737 - loss: 0.8805\n",
            "Epoch 7/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.7054 - loss: 0.8059\n",
            "Epoch 8/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - accuracy: 0.7309 - loss: 0.7426\n",
            "Epoch 9/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.7677 - loss: 0.6474\n",
            "Epoch 10/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.7994 - loss: 0.5598\n",
            "Epoch 11/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.8132 - loss: 0.5214\n",
            "Epoch 12/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.8395 - loss: 0.4504\n",
            "Epoch 13/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 32ms/step - accuracy: 0.8567 - loss: 0.4133\n",
            "Epoch 14/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.8655 - loss: 0.3767\n",
            "Epoch 15/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.8849 - loss: 0.3367\n",
            "Epoch 16/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.8948 - loss: 0.3013\n",
            "Epoch 17/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9068 - loss: 0.2724\n",
            "Epoch 18/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9132 - loss: 0.2519\n",
            "Epoch 19/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9200 - loss: 0.2338\n",
            "Epoch 20/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9317 - loss: 0.2066\n",
            "Epoch 21/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9400 - loss: 0.1835\n",
            "Epoch 22/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9412 - loss: 0.1774\n",
            "Epoch 23/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.9378 - loss: 0.1878\n",
            "Epoch 24/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.9516 - loss: 0.1516\n",
            "Epoch 25/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9560 - loss: 0.1352\n",
            "Epoch 26/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9573 - loss: 0.1305\n",
            "Epoch 27/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9617 - loss: 0.1199\n",
            "Epoch 28/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.9676 - loss: 0.0996\n",
            "Epoch 29/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9682 - loss: 0.0974\n",
            "Epoch 30/30\n",
            "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.9740 - loss: 0.0817\n",
            "\u001b[1m877/877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2970\n",
            "4.0s의 Test accuracy: 0.9167826175689697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.3607 - loss: 1.6284\n",
            "Epoch 2/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.4985 - loss: 1.2633\n",
            "Epoch 3/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.5622 - loss: 1.0929\n",
            "Epoch 4/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.5827 - loss: 1.0384\n",
            "Epoch 5/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.6345 - loss: 0.9429\n",
            "Epoch 6/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.7065 - loss: 0.7905\n",
            "Epoch 7/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.7476 - loss: 0.6960\n",
            "Epoch 8/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.7777 - loss: 0.6177\n",
            "Epoch 9/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.7913 - loss: 0.5787\n",
            "Epoch 10/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.8089 - loss: 0.5285\n",
            "Epoch 11/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.8264 - loss: 0.4761\n",
            "Epoch 12/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.8361 - loss: 0.4493\n",
            "Epoch 13/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.8533 - loss: 0.4041\n",
            "Epoch 14/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.8611 - loss: 0.3874\n",
            "Epoch 15/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.8735 - loss: 0.3535\n",
            "Epoch 16/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.8169 - loss: 0.5165\n",
            "Epoch 17/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8724 - loss: 0.3594\n",
            "Epoch 18/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8942 - loss: 0.3024\n",
            "Epoch 19/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8893 - loss: 0.3085\n",
            "Epoch 20/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.8624 - loss: 0.3849\n",
            "Epoch 21/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9020 - loss: 0.2806\n",
            "Epoch 22/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9073 - loss: 0.2614\n",
            "Epoch 23/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9199 - loss: 0.2311\n",
            "Epoch 24/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9258 - loss: 0.2164\n",
            "Epoch 25/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9310 - loss: 0.2037\n",
            "Epoch 26/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9351 - loss: 0.1930\n",
            "Epoch 27/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9368 - loss: 0.1872\n",
            "Epoch 28/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9433 - loss: 0.1681\n",
            "Epoch 29/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9201 - loss: 0.2354\n",
            "Epoch 30/30\n",
            "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.9436 - loss: 0.1673\n",
            "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9004 - loss: 0.3229\n",
            "5.0s의 Test accuracy: 0.8994114398956299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZAAAACUCAYAAAC9WX9uAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAA6zSURBVHhe7d3Lsdy2EoDhubcch7x2BspAey+cwInDpVI5jpOAFt6rHIjXdiL3qq3TNe1W40EABEHy/6qoIfFogI8BZoZzNP95//79/x4AAGz037dHAAA2YQIBADRhAgEANGEC2ej19fVtDQDurfsmempAfXl5eVsbS9prje37auPk8izf/oiYAHBGQyaQmQNja3tRPU3L5Vk+bURMADgrPsICADTZdQKRV9z6qOteTZ7Pt+k+L2WPV/68mwBwZ7u/A5EBXgZaWfxgX5vn8226zyuRsrpI3Vq58q0xAeDMhkwgdgDVRdkB1Q728libJ/x2K4mji+1njz1iAsDqhkwgdgDVBQBwbdxErxC9IwKAu7vNBLLHR0t8XAXgzqbcRFf2lbw81uYJvw0AONauf4muk4KW0QnCqskTmq8xrSgtYuMJWyeVV4rdEhMArmDX3wMpDb5ncIV9AIA98INSAIAmfAsLANCECQQA0IQJBADQ5GITyC+Pj6/yX6l8/LoGANjTgJvoMmh/eLx72/rm78eXl0+Pz29bzzKp9IiU/fPxUzbfxhJROyv1DwBWUBoXa8bN7gkkGnh9mu1IzaAaxbRS+TV9idJ0W6TatFLtq1I+ABypNC7qC+NU/nNcm/AR1ufHp5cvX5utccTgvHr/AGBN3EQHAGwkL5ZfV5pAel7dz3jl39M/ALiK51h38E10q2eArsmzZvfvez/+9vPbGgCM9devv7+tpeTGxWgss2nPeySd70BsUP0xKbmf8O7xYYmv0q7ePwCYrXdc1PvG72Z8CyuVZvXkb82rTbN68wFgFaUxcKlvYQEArogJBACwgbwb+fY/fnROIM/Pwj78E1CWmR/llD46Orp/ALCa0rhYn3/y3wMpTSAAgL2cfAIBAByFeyAAgCZMIACAJkwgAIAmTCAAgCY3m0Ce31/mvzEBgD6DvoVV+3XaqJymWT5OLn5NfZWKk4tvReVq2s/Fr6kPAOsZ8A4kGgAjUTk7sKb+U69c/Jr6ypaNBveSqFxN+7n4NfUBYE0DJhD9q8S9EB8AVjTpHsi3V9qPP846kJ69/wAw2i93uYluPyri3gIAjDDhJrrN8//PfFSvNk1pnuXL5eqLmviSd1T/v8cvGgLYS+0vGp78HYgdmM94E/rs/QdwZzu/A/Hppe2oTipN1JRN1bVq49fErk0TW8oCwAqeY9SkdyDyilr/T3ndPtMr7LP3HwBGe7f3BCJfYdWPZvTjGXGWV9dn7z8AjPYcFw++B6J/I6Gv8P0vX5WU6u/9cdDe/QeAdV38B6W4nwAAe+EXCQEATW7yh4QAgNGYQAAATZhAAABNbjmByLedAAB9htxE9wOyfD+4RqpeaoCvjStsDF9P8lr7KLb0A3OkrqWSVL3ovItUvm2vJW92e0ryo7RIT196YgrJ92k4XvcEEp3YmpOdq9d7sfj6pe0avX3yRse7s+hY1hzfrfU0L1dvZJ4aGdOmybrIlfFyMXN5kdp6si5ScXCcy32EFV2MepHiHFY8V9F1ZZ1lcLP9PLLPpeNpneXY3tFhE0jPRSEXn12OlOtLKk/XfXoNrZOql8uP8lLllK77ekLTfLqK8qOyqfq4ByaI81rmHYgMIvZC0oFHF6Xl7GLzZ8r1JZcn6/qo6zV8TI2ncvmlujm2rirF62lPyq9E98WSNLuMsFLM1no1JF50jm17q10DiC0xgUQXjGzbRcqk2LpR2VUuyN4+5OqnjqHI5dWIyubq59qTR3t+Vjk3W0mf7aL7pOt2kbQaNp7G0fTRMUta6/WY3R76HT6BRE8Gv23pxZW7wGyZKP5Ith1ZVE0/W0RtHWWlvrTw18mI/ZAYEtcuNXGlXEprzFa5vmjbdlG5PFzToROIXGC5izVF6tiLNaJlWuJvYdvx7en2qCeTHi/fzhFG9EVjeCOOVS27D6m+ROl3ljtmuTzB8byWwyaQ3IVUO4DoRTpzwGlxln7OwrH43krHY3ZfuBbOa8oEMvICycWSvNKyN21j77Z8/GhQ1u1cnpdKz/F1atuTcpFUeo+o/ZZ9vbvcMeN43s+Uv0SX/CgtouVyMUvtlUT9KUnV6emn5m/pi60T1bdtptoTuTqyrfl23dN6WkfXlY9r5eK2sG2J2vb2qHeWPCH5Pk2s1J5I1cOxbvl7IFyMx9GBguMPnB8/KAUAaLLE34EAAM6HCQQA0IQJBADQZPgE4r9NsbfZ7bXiuKyPY7YGntOxFY/LJd+BnOXE5upFeStdQHv1ReLaZYtU+Z6Ylq/bE+toZ+n7mY/xDEcfn6ETiOzMzK9nzm6v1ZmPy8wLVPttl9r2U+VqY2q5vdXuz13NOg+9Zvdz1ePCPZBFneFJtJIjjhfnCHe36wQSvdqyabJuF0u3o7weuXia5/NT6XvKtbW1L1o2qhfFseX1MVXOLl6Ubsv7vBUH5KifKpduF6XrPr2kVE/TozxRylc2v1TH5tkymm7zVS5vC1s3F1O3U3lRurB5UX5Krp5uR3lC06O8Fql4UXybZuv5srpt8374598BJOCWASAq79NyMbe2J2ydUlu6XSpXsrV8iY0XxU61V6oXkTK5sj491YaPYdej+JKmfN4eoj4Ivw81UvsjabKk2irxfYnWxdZt1RpT1pUvJzQtl6eiMp4t0xozV2ZUTFFTT5TKpeqltNaPypViLfURlu98zU7X8jsu65ImogOn2yP7MEJqH0pS9XyM6Fhs5WP4NkqkvC5b6o0U7UOrmrrSXrQo3xfNy8WWMj4/Ku/LbYmZK1uytW60PyVR+RExavh6UZzac7RFrr7kSZtq6zH1ZQ+bQHRH7M6sSvt5hr7iWK3XtdSLlho916fUidppjWnr2brShk/bQuqV+rkldqpOaz9792807cvW/th6NXWHTCDSUHRyS6ROy4Fvba+FtqXLFjP7KXrbm93fFeyxzxJPFokty560/7pskepbT0xbz9fX7ei4aJuRVD+FxrRLSWn/NH1rP3P1WuXaS9E6uqREsW09XXKW+AhLOzrqoGObVY791c7/6td1S/98+ZZ929puSz9HaG33qP7WGtm3qROI7fQRF4NvX9JEdECj/s3ucyS1DyU19WpjlfjjuaWfJTbunqJ9qLFX/3xfouPp2/b7IKL+ReVUrrwsUT8srZ+Kv0Wun2prO758az9b69Weo1a5WKVzJ0p96f7v3KWBXEdsB/RgaXnfORsnFbfUnsiV0TZTsZXvi5C0qH7UXpTm5crkYsqjsPk1saJ6qlRflNrzaTX1UnVUqQ0rlZeKmYultK6U8+W3tqdszBraTqqeTY/KaJrQdI1p2bRUzNp6ypZN5UUxVW97ubhC8u26SMXMxROpemJL3dr2RKqMxpM8u65K9VSpzu4TyGiz22u10nEp5YkzHNPRuJba6DWjevvGeYjt0Z6eu1Fx+UEpAECTpf4OBABwHkwgAIAmTCAAgCZMIACAJkwgjv+GiYjS8HTH48M1ATCB/IsMCtHX2yRt9oDR2t4R/Rz1lcDZfe9xxDUBrIYJ5CYY7ACMxgTypvRKevYrztZX9aPeDdQoHbOrm31NAKs5dAKRJ59dVPSk1DT7mCpnF0u3o7zVRP3Tfuf6n6qnj6l6e8i1VdsP2/foUcm2Lp6tk8q3ZZSm23wAT4dNIPKElFdwdql9ktq6tk5NTFvmjHL7lqL7qvXOQs9ViT/v0XFJnXebbuv5mD4fwGIfYcmTtIYtt/WJXdsG2sn50HNi10Uuz5L0lushJSrj2yjFqe0PcBeHTSDyZMwNIK005h6xUUfOrQ62dl3k8pSctyg9Z/Q5l/ZHxgOu6NB3IDqAjH7i+wXzyfmUYx+d11LeVhpv9PnWeBK/pV/A1S3xEZZ9ouIadCDXR6uUJ4u/FjTNPvby7aSuPynnywI4+CZ6LV/WP+lzg0ltO6UBItdObRtXs+eg2hp7ax1tRxZ7fmvi+DrA3SxxD0QXfTL6PP8ktfk2z9fz+Xdmj81ZaJ9L7L7p+a6pp2WkjtZTNqYuvgxwd6f7Qam9n8hR/JY2pU5EB6bIEQPUiH62HJ9V+H2s3Y8z7zMwCr9ICABossRNdADA+TCBAACaMIEAAJowgQRSN48BAE/dN9Frv6kzSu+3X2rq+zJ+H2vzAODKhkwgMwfNnvZ0sM/V9/Gj9jQtlwcAV3erj7AY2AFgnF0nEHk1ro+67tXk+Xyb7vNGY9IBgNju70BkgJdBWBY/2Nfm+Xyb7vN6aJsRydMlVQYA7mTIBGIHV12UHWztYC+PtXnCb88m7eti9w8A7mrIBGIHV10AANd2q5voOdG7HgBAGhNIAR9XAUBsyk10ZV/ly2NtnvDbAIBj7fqX6DopaBmdIKyaPKH5GtOK0lJa6tt+CFs2lwcAV7br74FsGdiPdJZ+AsBK+EEpAEATbqIDAJowgQAAmjCBAACaXGwC+eXx8VX+K5WPX9cAAHsafBNdBvAPj3ePvx9fXj49Pv8rzRqZb0XtW0f3DwBWMGZcGziB2Aa1IU2LOiZpfz5+6sq3O5NKV5ovtExUZ0v7W/oHACvoHfee4xr3QAAATQZNIN9mp8cfX77OTytavX8AMMvnx6cX+V/Tez4hkTH19SrvQOK3VwCAlG+TgPxPHK+bxs/neDvgHogdvP1nZ9HA7tN029pSP5WmbN5R/fvej7/9/LYGAGP99evvb2u17LhVf+/34HcgtlP6Y1TyMdO7x4d/voorb7V0286Us6zePwAYrTSuPfM734H4V9ulbV+n/m7/U00bqlQ2qmvTRvQPAFbXNq4NegeiM5U0oNsr/THf6v0DgFlkMpDxsH8M7JxA9G6+/XhHjHr13bujq/cPAFZTGtee+Sf/S/SovZzZ/QOAFY0Z9wZPILPpTjJgA8BsJ59AAABHucgfEgIAZmMCAQA0YQIBADRhAgEANGECCcif7gMA8rq/hZUabOUP9/Yg7bXG9n1NxfFt5OrVxgSAqxkygcwcNFvbi+rVpOXK1MYEgCviIywAQJNdJxB5Na6Puu7V5Pl8m+7zUlrfFfBuAgAij8f/ARgIATpv8UedAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "iqylajyH8AXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "9bNg8jnQ8Jer"
      }
    }
  ]
}